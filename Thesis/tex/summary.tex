%# -*- coding: utf-8-unix -*-
%%==================================================
%% conclusion.tex for SJTUThesis
%% Encoding: UTF-8
%%==================================================

\begin{summary}
\section{全文总结回顾}
本文基于眼动数据在图像质量评价中越来越被重视这一事实，探讨了当前的眼动数据的应用方法，提出了眼动数据和立体图像之间是否存在其他关联这一研究问题。文章首先对立体图像质量评价的方法进行了综述，特别对眼动数据的应用方式和方法进行了回顾，讨论了目前在2D和3D图像质量评价中眼动数据的应用模式，发现没有相关研究直接利用眼动数据建立图像质量评价模型。文章从眼睛的生理视觉的角度出发，探讨了眼动过程中视觉系统的活动与图像质量评价、眼动数据之间的关系，为最后的特征提取提供理论依据。

本文的主要工作包括：
第一，针对目前还没有符合研究目的的立体图像库，本文首先采用了移轴的方法对选取的图像进行了出入屏调整，从而得到了立体图像库。又针对当前的软件功能与本文需求不否的事实，开发了眼动数据收集软件。该软件包括了单刺激、双刺激、移轴等三种测试模式，并且可以进行线上线下的任务管理与数据存储，为数据采集与应用提供了便利。文章的基础是眼动数据，为了保障数据收集的可信度与精度，本文用三个实验来达到这一要求，分别是立体视敏度检验与主观确定实验、3D校正实验和立体图像眼动实验。实验的过程中测试结果不符合要求的被试未安排测试，保证了数据的可信度。最终获取了用于实验的图像与眼动数据库。

第二，数据处理，首先对主观评分进行了处理，主要是进行了异常值检测，获取了每幅图像对应的MOS值。眼动数据的处理是重点，文章针对现有的眼动数据处理技术处理3D场景时表现的不足，对现有的技术进行了改进。首先在校正环节增加了3D校正过程，通过3D实验获取的眼动数据的测量值与预设值之间的差异，获取被试的系统偏差，利用该偏差校正被试观看立体图像的眼动数据，提高了眼动数据的精度，特别是深度方向的精度；然后本文改进了滤波算法，将2D情形下眼动滤波的算法针对3D特征进行了重写。对眼动数据以不同的眼睛作为参考进行了滤波，结合第五章的实验结果，给出了参考辅眼滤波的建议。最后，本文给出了一种立体注视密度图的创建方法来表示3D场景下的眼动数据注视图。该方法采用了基于视差图分层的思想，将立体图像分割并排布在近似的深度平面上，同时将眼动数据也进行了类似的分层，然后在各层创建2D注视密度图，最终整合形成立体注视密度图。这种图既能表示图像内容，也能表示图像在给定条件下的深度和眼睛注视的深度。结合这些图，我们观察到了一些与生理学成果相统一的测试结果。为眼动数据特征提取提供了思路。

第三，本文从三个方面提取了眼动数据特征，包括注视等过程的静态特征、扫视过程的动态特征以及眼动数据的视差特征。利用SVR回归对提取的特征与图像的MOS值进行了拟合，证明了眼动数据与图像特征是有关联的。
\section{研究展望}
虽然本文在眼动数据的收集、处理以及应用等方面取得了一些初步成果，但是无论从研究的深度还是广度，仍然有一些问题值得深究，这里将列举其中一些以供其他研究人员参考。本文后续的研究点包括：
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item 数据的采集部分，本文在数据采集时采用了自建的图像库，图像数量较少，相对来说，场景比较少，影响图像质量的因素单一。因此，未来可以利用公开的3D图像库，在特征更加丰富的图像库下进行眼动实验，期望可以得到更好更普遍的结果；
\item 眼动数据的基础技术部分。本文在滤波时，仍然采用了屏幕上视点间的距离，这种方法的效果符合测量实际，但未来可以考虑直接估计空间中的视点，然后以空间中视点间的距离为依据进行滤波，这样更符合立体实际。另外，本文在分离眼动过程时，假设了扫视过程是固定长度，这和实际情况多少有些出入，未来可以研究当扫视过程是可变长度时如何分离眼动过程；
\item 最后，在眼动数据特征提取时，本文只是针对了数据的基础属性，如注视区域、视差、扫视过程等，在利用眼动数据模拟人眼视觉过程方面并没有提出有价值的特征，这可以作为以后研究的重点。只有将眼动数据与人眼视觉系统进行统和建模，才能发挥出眼动数据最大的价值。
\end{itemize}

\end{summary}
